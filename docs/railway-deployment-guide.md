# Unified AI Platform: Railway Deployment Guide

This comprehensive guide outlines how to deploy the Unified AI Platform on Railway using prebuilt Docker containers.

## Table of Contents

- [System Components](#system-components)
- [Architecture Overview](#architecture-overview)
- [Prerequisites](#prerequisites)
- [Deployment Process](#deployment-process)
  - [Step 1: Create a Railway Project](#step-1-create-a-railway-project)
  - [Step 2: Deploy Core Services](#step-2-deploy-core-services)
  - [Step 3: Configure Service Connectivity](#step-3-configure-service-connectivity)
  - [Step 4: Set Up Domains and Security](#step-4-set-up-domains-and-security)
  - [Step 5: Final Testing](#step-5-final-testing)
- [Environment Variables Reference](#environment-variables-reference)
- [Post-Deployment Tasks](#post-deployment-tasks)
- [Troubleshooting](#troubleshooting)
- [Monitoring and Maintenance](#monitoring-and-maintenance)

## System Components

The unified AI platform consists of several containerized services working together:

| Application | Purpose | Docker Image | Notes |
| :-- | :-- | :-- | :-- |
| **OpenWebUI** | Frontend UI | ghcr.io/open-webui/open-webui:latest | User interface for all AI interactions |
| **LiteLLM** | Universal model proxy | ghcr.io/berriai/litellm:main | Provides unified access to AI models |
| **PostgreSQL** | Database for LiteLLM | PostgreSQL (Railway managed) | Stores LiteLLM configuration and logs |
| **Redis** | Caching layer | redis:alpine | Improves performance and reduces API costs |
| **Jupyter** | Code execution | jupyter/minimal-notebook | Executes code generated by AI models |
| **Tika** | Document extraction | apache/tika:latest-full | Extracts text from various file formats |
| **SearXNG** | Private search engine | searxng/searxng | Provides web search capabilities |

## Architecture Overview

```mermaid
graph TD
    User[User Browser] --> OWU[OpenWebUI]
    
    subgraph "Railway Project"
        OWU --> LITELLM[LiteLLM]
        OWU --> TIKA[Tika]
        OWU --> JUPYTER[Jupyter]
        OWU --> SEARXNG[SearXNG]
        
        LITELLM --> POSTGRES[PostgreSQL]
        LITELLM --> REDIS[Redis]
        LITELLM -->|"Text Models"| OPENROUTER[OpenRouter API]
        LITELLM -->|"Image Models"| EDENAI[Eden AI API]
        
        SEARXNG --> REDIS
    end
    
    style User fill:#4CAF50
    style OWU fill:#2196F3
    style LITELLM fill:#FF9800
    style POSTGRES fill:#607D8B
    style REDIS fill:#795548
    style OPENROUTER fill:#9C27B0
    style EDENAI fill:#E91E63
    style JUPYTER fill:#607D8B
    style TIKA fill:#009688
    style SEARXNG fill:#3F51B5
```

## Prerequisites

Before you begin deployment on Railway, you'll need:

- [Railway account](https://railway.app) with appropriate subscription tier
- API keys for model providers:
  - [OpenRouter](https://openrouter.ai) for text generation models
  - [EdenAI](https://edenai.co) for image generation models (optional)

## Deployment Process

### Step 1: Create a Railway Project

1. Log in to your Railway account
2. Create a new project by clicking "New Project"
3. Choose a name for your project (e.g., "unified-ai-platform")

### Step 2: Deploy Core Services

Each service will be deployed as a separate service within your Railway project using official pre-built Docker images.

#### Deploy LiteLLM Postgres Database

1. In your Railway project, click "New Service" → "Database" → "PostgreSQL"
2. Select appropriate region and plan
3. Once created, copy the PostgreSQL connection string from the "Connect" tab

#### Deploy LiteLLM Service

1. In your Railway project, click "New Service" → "Deploy from image"
2. Enter Docker image: `ghcr.io/berriai/litellm:main`
3. Set environment variables:
   - `PORT=4000`
   - `LITELLM_PORT=4000`
   - `LITELLM_HOST=0.0.0.0`
   - `LITELLM_MASTER_KEY=[generate a secure key]` (e.g., using `openssl rand -hex 32`)
   - `LITELLM_ADMIN_UI=true`
   - `DATABASE_URL=[PostgreSQL connection string from previous step]`
   - `STORE_MODEL_IN_DB=True`
   - Optional: `OPENROUTER_API_KEY=[your OpenRouter API key]`
   - Optional: `EDENAI_API_KEY=[your EdenAI API key]`

#### Deploy Redis Service

1. In your Railway project, click "New Service" → "Deploy from image"
2. Enter Docker image: `redis:alpine`
3. No environment variables needed

#### Deploy Apache Tika Service

1. In your Railway project, click "New Service" → "Deploy from image"
2. Enter Docker image: `apache/tika:latest-full`
3. No environment variables needed

#### Deploy SearXNG Service

1. In your Railway project, click "New Service" → "Deploy from image"
2. Enter Docker image: `searxng/searxng`
3. Set environment variables:
   - `BASE_URL=[will be automatically set by Railway]`
   - `INSTANCE_NAME=Unified AI Platform Search`
   - `SEARXNG_SECRET_KEY=[generate a secure key]` (e.g., using `openssl rand -hex 32`)

#### Deploy JupyterLab Service

1. In your Railway project, click "New Service" → "Deploy from image"
2. Enter Docker image: `jupyter/minimal-notebook:latest`
3. Set environment variables:
   - `JUPYTER_PASSWORD=[generate a secure password]`
   - `JUPYTER_ENABLE_LAB=yes`

#### Deploy OpenWebUI Service

1. In your Railway project, click "New Service" → "Deploy from image"
2. Enter Docker image: `ghcr.io/open-webui/open-webui:latest`
3. Set environment variables (initial configuration):
   - `PORT=8080`
   - `WEBUI_NAME=Unified AI Platform`
   - `WEBUI_AUTH=true`
   - `WEBUI_SECRET_KEY=[generate a secure key]` (e.g., using `openssl rand -hex 32`)
   - `ENABLE_SIGNUP=true`
   - `ENABLE_LOGIN_FORM=true`
   - `DEFAULT_USER_ROLE=admin`

### Step 3: Configure Service Connectivity

After all services are deployed, you need to configure them to communicate with each other using Railway's reference variables for proper visualization in the Architecture UI.

#### Set Up Domain Names

1. For each service that needs external access, go to the service settings → "Domains" → "Generate Domain"
2. Note the generated domain names for each service

#### Update OpenWebUI Environment Variables

Once all services have domains, update the OpenWebUI service with these additional environment variables:

```
# API Connection - Use reference variables
OPENAI_API_BASE_URL=https://${{litellm-ruOg.RAILWAY_PUBLIC_DOMAIN}}/v1
OPENAI_API_KEY=[your LITELLM_MASTER_KEY]

# Document Processing
CONTENT_EXTRACTION_ENGINE=tika
TIKA_SERVER_URL=https://${{tika.RAILWAY_PUBLIC_DOMAIN}}
RAG_EMBEDDING_ENGINE=openai
RAG_EMBEDDING_MODEL=text-embedding-3-small
CHUNK_SIZE=1000
CHUNK_OVERLAP=100

# Web Search
ENABLE_RAG_WEB_SEARCH=true
RAG_WEB_SEARCH_ENGINE=searxng
SEARXNG_QUERY_URL=https://${{searxng.RAILWAY_PUBLIC_DOMAIN}}/search?q=<query>
RAG_WEB_SEARCH_RESULT_COUNT=3

# Code Execution
JUPYTER_SERVER_URL=https://${{JupyterLab.RAILWAY_PUBLIC_DOMAIN}}
JUPYTER_TOKEN=[your JUPYTER_PASSWORD]
ENABLE_CODE_EXECUTION=true

# Image Generation (optional)
ENABLE_IMAGE_GENERATION=true
IMAGE_GENERATION_ENGINE=openai
```

#### Update LiteLLM Environment Variables

Add Redis connection to LiteLLM service using reference variables:

```
REDIS_HOST=${{redis.RAILWAY_PRIVATE_DOMAIN}}
REDIS_PORT=${{redis.RAILWAY_TCP_APPLICATION_PORT}}
```

Using reference variables as shown above ensures that:
1. Service connections are visible in the Railway Architecture UI
2. Services automatically adapt to any domain or configuration changes
3. Your deployment follows Railway best practices for service connectivity

### Step 4: Set Up Domains and Security

1. For LiteLLM, create a TCP proxy for port 4000 to allow OpenWebUI to connect properly
2. For Redis, create a TCP proxy for port 6379 to allow LiteLLM to connect properly
3. Configure JupyterLab to use proper authentication

### Step 5: Final Testing

1. Access the OpenWebUI through its domain
2. Create an account (if enabled) or use the default admin account
3. Test text generation with various models
4. Test document upload and extraction with Tika
5. Test web search functionality with SearXNG
6. Test code execution with JupyterLab

## Environment Variables Reference

### OpenWebUI Environment Variables

| Variable | Purpose | Example Value |
|----------|---------|---------------|
| `OPENAI_API_BASE_URL` | URL for LiteLLM API | `https://litellm-domain/v1` |
| `OPENAI_API_KEY` | Authentication key for LiteLLM | `[your LITELLM_MASTER_KEY]` |
| `CONTENT_EXTRACTION_ENGINE` | Document processing engine | `tika` |
| `TIKA_SERVER_URL` | URL for Apache Tika | `https://tika-domain` |
| `ENABLE_RAG_WEB_SEARCH` | Enable web search | `true` |
| `RAG_WEB_SEARCH_ENGINE` | Web search provider | `searxng` |
| `SEARXNG_QUERY_URL` | URL for SearXNG | `https://searxng-domain/search?q=<query>` |
| `JUPYTER_SERVER_URL` | URL for JupyterLab | `https://jupyter-domain` |
| `JUPYTER_TOKEN` | Authentication for JupyterLab | `[your JUPYTER_PASSWORD]` |

### LiteLLM Environment Variables

| Variable | Purpose | Example Value |
|----------|---------|---------------|
| `LITELLM_MASTER_KEY` | Authentication key | `[secure random string]` |
| `DATABASE_URL` | PostgreSQL connection | `postgresql://user:pass@host:port/db` |
| `REDIS_HOST` | Redis hostname | `redis.railway.internal` |
| `REDIS_PORT` | Redis port | `6379` |
| `OPENROUTER_API_KEY` | OpenRouter API access | `[your key]` |
| `EDENAI_API_KEY` | EdenAI API access | `[your key]` |
| `UI_USERNAME` | LiteLLM UI admin username | `admin_username` |
| `UI_PASSWORD` | LiteLLM UI admin password | `your_secure_password` |

### JupyterLab Environment Variables

| Variable | Purpose | Example Value |
|----------|---------|---------------|
| `JUPYTER_PASSWORD` | Authentication password | `[secure password]` |
| `JUPYTER_ENABLE_LAB` | Enable JupyterLab interface | `yes` |
| `RESTARTABLE` | Allow service restart | `yes` |

## Post-Deployment Tasks

### Configure LiteLLM Models

1. Access the LiteLLM admin interface at `https://[litellm-domain]/admin`
2. Add and configure models from various providers

### Set Up OpenWebUI Admin

1. Access OpenWebUI and create an admin account
2. Configure model settings, user permissions, and other system settings

### Configure Persistent Storage

1. Create and attach volumes for each service that needs persistent storage:
   - OpenWebUI for user data
   - JupyterLab for notebooks and scripts
   - SearXNG for configuration

## Troubleshooting

### Common Issues

1. **Connection Problems**: Ensure internal URLs are using `.railway.internal` domains
2. **Authentication Errors**: Verify API keys and authentication tokens
3. **Missing Models**: Check LiteLLM configuration and API provider keys
4. **Document Processing Fails**: Verify Tika is running and accessible

### Checking Service Logs

1. Navigate to the service in Railway dashboard
2. Go to the "Logs" tab to see runtime logs

### LiteLLM Authentication Issues

If you encounter authentication errors with the LiteLLM UI:

1. Check that both `UI_USERNAME` and `UI_PASSWORD` are correctly set without quotes
2. Ensure that the password doesn't contain special characters that might need escaping
3. Restart the LiteLLM service after making any changes

Example error message:
```
{"error":{"message":"Invalid credentials used to access UI.\nCheck 'UI_USERNAME', 'UI_PASSWORD' in .env file","type":"auth_error","param":"invalid_credentials","code":"401"}}
```

### JupyterLab Integration Issues

For problems connecting OpenWebUI to JupyterLab:

1. Verify that JupyterLab is running and accessible via its URL
2. Ensure the same password is used in both JupyterLab's `JUPYTER_PASSWORD` and OpenWebUI's `JUPYTER_PASSWORD`
3. OpenWebUI must have both `JUPYTER_SERVER_URL` and `JUPYTER_PASSWORD` configured
4. The authentication method in JupyterLab must be password-based (configured automatically)

### SearXNG Configuration Issues

If web search is not working correctly:

1. Ensure `ENABLE_RAG_WEB_SEARCH` is set to `true` in OpenWebUI
2. Verify that `RAG_WEB_SEARCH_ENGINE` is set to `searxng`
3. Check that the `SEARXNG_QUERY_URL` has the correct format with the `<query>` placeholder:
   ```
   SEARXNG_QUERY_URL=https://[your-searxng-domain]/search?q=<query>
   ```
4. Set an appropriate `RAG_WEB_SEARCH_RESULT_COUNT` (recommended: 3-5)
5. Validate that SearXNG service is running and accessible

## Monitoring and Maintenance

### Regular Backups

1. Regularly back up volumes using Railway CLI or UI
2. Export important configurations and data

### Service Updates

1. To update a service, deploy a new version of the Docker image
2. Monitor for any breaking changes in new versions 